{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e80de323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from tensorflow.keras.models import load_model\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from lime import lime_image\n",
    "import shap\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import io\n",
    "from skimage.transform import resize\n",
    "from PIL import Image\n",
    "\n",
    "#pip install tensorflow numpy matplotlib datasets scikit-image lime shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cbc48100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model loaded successfully!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\n",
      "Loaded 20 test images for explanation\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create directory for saving explanation images\n",
    "os.makedirs('explanations', exist_ok=True)\n",
    "\n",
    "# Constants\n",
    "img_size = 224\n",
    "batch_size = 32\n",
    "num_classes = 4\n",
    "\n",
    "# Function to preprocess images\n",
    "def preprocess_image(image):\n",
    "    if isinstance(image, bytes):  # If it's bytes from parquet\n",
    "        image = Image.open(io.BytesIO(image))\n",
    "    if hasattr(image, 'convert'):  # If it's a PIL image\n",
    "        image = image.convert('RGB').resize((img_size, img_size))\n",
    "        image = np.array(image)\n",
    "    return image / 255.0\n",
    "\n",
    "# Load the trained model\n",
    "try:\n",
    "    model = load_model('best_model.h5')  # Try loading the best model first\n",
    "    print(\"Best model loaded successfully!\")\n",
    "except:\n",
    "    model = load_model('alzheimer_classifier.h5')  # Fallback to the final model\n",
    "    print(\"Fallback model loaded successfully!\")\n",
    "\n",
    "# Class names for reference\n",
    "class_names = ['Mild_Demented', 'Moderate_Demented', 'Non_Demented', 'Very_Mild_Demented']\n",
    "\n",
    "# Load test data from local parquet file\n",
    "def load_local_test_data(parquet_path, num_samples=20):\n",
    "    df = pd.read_parquet(parquet_path)\n",
    "    \n",
    "    if num_samples:\n",
    "        df = df.sample(n=num_samples, random_state=40)  # << Randomly sample\n",
    "    \n",
    "    test_images_raw = []\n",
    "    test_labels = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        # Handle different possible column names\n",
    "        img_bytes = row.get('image', row.get('bytes', None))\n",
    "        if isinstance(img_bytes, dict):  # If stored as dictionary with 'bytes' key\n",
    "            img_bytes = img_bytes['bytes']\n",
    "        \n",
    "        test_images_raw.append(img_bytes)\n",
    "        test_labels.append(row['label'])\n",
    "    \n",
    "    test_images = np.array([preprocess_image(img) for img in test_images_raw])\n",
    "    test_labels = np.array(test_labels)\n",
    "    \n",
    "    return test_images, test_labels\n",
    "\n",
    "# Load local test data (adjust path as needed)\n",
    "test_images, test_labels = load_local_test_data('Dataset/Data/test.parquet', num_samples=20)\n",
    "\n",
    "# Get predictions for these samples\n",
    "predictions = model.predict(test_images)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "print(f\"Loaded {len(test_images)} test images for explanation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09724fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n===== Generating LIME explanations =====\")\n",
    "\n",
    "# Enhanced LIME explainer configuration\n",
    "explainer = lime_image.LimeImageExplainer(\n",
    "    kernel_width=0.25,  # Controls the size of the neighborhood\n",
    "    verbose=False,      # Set to True for debugging\n",
    "    random_state=42     # For reproducibility\n",
    ")\n",
    "\n",
    "def lime_predict(images):\n",
    "    \"\"\"Enhanced prediction function for LIME\"\"\"\n",
    "    # Convert to float32 if needed (some models require this)\n",
    "    if images.dtype != np.float32:\n",
    "        images = images.astype(np.float32)\n",
    "    # Handle single image case\n",
    "    if len(images.shape) == 3:\n",
    "        images = np.expand_dims(images, axis=0)\n",
    "    # Ensure proper normalization (already done in preprocessing, but double-check)\n",
    "    if images.max() > 1.0:\n",
    "        images = np.clip(images / 255.0, 0, 1)\n",
    "    return model.predict(images)\n",
    "\n",
    "for i in range(5):    \n",
    "    image = test_images[i]\n",
    "    true_label = test_labels[i]\n",
    "    pred_label = predicted_classes[i]\n",
    "    pred_prob = predictions[i][pred_label]\n",
    "    \n",
    "    print(f\"True: {class_names[true_label]} | Predicted: {class_names[pred_label]} ({pred_prob:.2f})\")\n",
    "    \n",
    "    try:\n",
    "        # Enhanced explanation parameters\n",
    "        explanation = explainer.explain_instance(\n",
    "            image.astype('double'),  # LIME works better with double precision\n",
    "            lime_predict,\n",
    "            top_labels=3,            # Show top 3 classes\n",
    "            hide_color=0, \n",
    "            num_samples=2000,        # Increased for better quality\n",
    "            batch_size=32,           # Process in batches for efficiency\n",
    "            distance_metric='cosine', # Better for image data\n",
    "            segmentation_fn=None     # Use default quickshift segmentation\n",
    "        )\n",
    "        \n",
    "        # Get explanation for both positive and negative features\n",
    "        temp, mask = explanation.get_image_and_mask(\n",
    "            pred_label,\n",
    "            positive_only=False,     # Show both positive and negative features\n",
    "            num_features=4,         # Optimal number of superpixels to show\n",
    "            hide_rest=False,\n",
    "            min_weight=0.05          # Filter out insignificant features\n",
    "        )\n",
    "        \n",
    "        # Create enhanced visualization\n",
    "        lime_explanation = mark_boundaries(\n",
    "            temp,  # Adjust brightness for better visibility\n",
    "            mask,\n",
    "            color=(1, 1, 1),  # White boundaries\n",
    "        )\n",
    "        \n",
    "        # Create more informative title\n",
    "        title = (f\"LIME Explanation\\n\"\n",
    "                f\"True: {class_names[true_label]}\\n\"\n",
    "                f\"Pred: {class_names[pred_label]} ({pred_prob:.2f})\\n\"\n",
    "                f\"Top Features Highlighted\")\n",
    "        \n",
    "        # Enhanced display function\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Original Image\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(image)\n",
    "        plt.title(f\"Original\\n{class_names[true_label]}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # LIME Explanation\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(lime_explanation)\n",
    "        plt.title(f\"Explanation\\n{class_names[pred_label]}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"explanations/lime_explanation_{i}.png\", bbox_inches='tight', dpi=150)\n",
    "        plt.close()\n",
    "        \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Failed for image {i}: {str(e)}\")\n",
    "        if 'image' in locals():\n",
    "            print(f\"Image shape: {image.shape}, dtype: {image.dtype}, range: [{image.min()}, {image.max()}]\")\n",
    "        continue\n",
    "\n",
    "print(\"\\nLIME explanation generation completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "30ded8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv2 could not be imported!\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 67\u001b[39m\n\u001b[32m     64\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExplanation saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexplanation_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# Generate explanations for the first 5 images\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m \u001b[43mexplain_with_shap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_explanations\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mSHAP explanations completed successfully!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     70\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExplanation images saved to \u001b[39m\u001b[33m'\u001b[39m\u001b[33mexplanations\u001b[39m\u001b[33m'\u001b[39m\u001b[33m directory\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mexplain_with_shap\u001b[39m\u001b[34m(model, images, class_names, num_explanations)\u001b[39m\n\u001b[32m     14\u001b[39m     images = images[:num_explanations]\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Create a masker that is used to mask out partitions of the input image\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m masker = \u001b[43mshap\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmaskers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minpaint_telea\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Create an explainer with the model and image masker\u001b[39;00m\n\u001b[32m     20\u001b[39m explainer = shap.Explainer(model, masker, output_names=class_names)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\silen\\personal-folder\\XAI-project-vu\\env\\Lib\\site-packages\\shap\\maskers\\_image.py:58\u001b[39m, in \u001b[36mImage.__init__\u001b[39m\u001b[34m(self, mask_value, shape)\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28mself\u001b[39m.mask_value = mask_value.flatten()\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mask_value, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     \u001b[43massert_import\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcv2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m     \u001b[38;5;28mself\u001b[39m.mask_value = mask_value\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m mask_value.startswith(\u001b[33m\"\u001b[39m\u001b[33mblur(\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\silen\\personal-folder\\XAI-project-vu\\env\\Lib\\site-packages\\shap\\utils\\_general.py:26\u001b[39m, in \u001b[36massert_import\u001b[39m\u001b[34m(package_name)\u001b[39m\n\u001b[32m     24\u001b[39m msg, e = import_errors[package_name]\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(msg)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 67\u001b[39m\n\u001b[32m     64\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExplanation saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexplanation_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# Generate explanations for the first 5 images\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m \u001b[43mexplain_with_shap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_explanations\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mSHAP explanations completed successfully!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     70\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExplanation images saved to \u001b[39m\u001b[33m'\u001b[39m\u001b[33mexplanations\u001b[39m\u001b[33m'\u001b[39m\u001b[33m directory\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mexplain_with_shap\u001b[39m\u001b[34m(model, images, class_names, num_explanations)\u001b[39m\n\u001b[32m     14\u001b[39m     images = images[:num_explanations]\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Create a masker that is used to mask out partitions of the input image\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m masker = \u001b[43mshap\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmaskers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minpaint_telea\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Create an explainer with the model and image masker\u001b[39;00m\n\u001b[32m     20\u001b[39m explainer = shap.Explainer(model, masker, output_names=class_names)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\silen\\personal-folder\\XAI-project-vu\\env\\Lib\\site-packages\\shap\\maskers\\_image.py:58\u001b[39m, in \u001b[36mImage.__init__\u001b[39m\u001b[34m(self, mask_value, shape)\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28mself\u001b[39m.mask_value = mask_value.flatten()\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mask_value, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     \u001b[43massert_import\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcv2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m     \u001b[38;5;28mself\u001b[39m.mask_value = mask_value\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m mask_value.startswith(\u001b[33m\"\u001b[39m\u001b[33mblur(\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\silen\\personal-folder\\XAI-project-vu\\env\\Lib\\site-packages\\shap\\utils\\_general.py:26\u001b[39m, in \u001b[36massert_import\u001b[39m\u001b[34m(package_name)\u001b[39m\n\u001b[32m     24\u001b[39m msg, e = import_errors[package_name]\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(msg)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "    \u001b[31m[... skipping similar frames: <module> at line 67 (1 times), Image.__init__ at line 58 (1 times), assert_import at line 26 (1 times), explain_with_shap at line 17 (1 times), InteractiveShell.run_code at line 3670 (1 times)]\u001b[39m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 67\u001b[39m\n\u001b[32m     64\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExplanation saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexplanation_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# Generate explanations for the first 5 images\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m \u001b[43mexplain_with_shap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_explanations\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mSHAP explanations completed successfully!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     70\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExplanation images saved to \u001b[39m\u001b[33m'\u001b[39m\u001b[33mexplanations\u001b[39m\u001b[33m'\u001b[39m\u001b[33m directory\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mexplain_with_shap\u001b[39m\u001b[34m(model, images, class_names, num_explanations)\u001b[39m\n\u001b[32m     14\u001b[39m     images = images[:num_explanations]\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Create a masker that is used to mask out partitions of the input image\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m masker = \u001b[43mshap\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmaskers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minpaint_telea\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Create an explainer with the model and image masker\u001b[39;00m\n\u001b[32m     20\u001b[39m explainer = shap.Explainer(model, masker, output_names=class_names)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\silen\\personal-folder\\XAI-project-vu\\env\\Lib\\site-packages\\shap\\maskers\\_image.py:58\u001b[39m, in \u001b[36mImage.__init__\u001b[39m\u001b[34m(self, mask_value, shape)\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28mself\u001b[39m.mask_value = mask_value.flatten()\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mask_value, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     \u001b[43massert_import\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcv2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m     \u001b[38;5;28mself\u001b[39m.mask_value = mask_value\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m mask_value.startswith(\u001b[33m\"\u001b[39m\u001b[33mblur(\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\silen\\personal-folder\\XAI-project-vu\\env\\Lib\\site-packages\\shap\\utils\\_general.py:26\u001b[39m, in \u001b[36massert_import\u001b[39m\u001b[34m(package_name)\u001b[39m\n\u001b[32m     24\u001b[39m msg, e = import_errors[package_name]\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(msg)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\silen\\personal-folder\\XAI-project-vu\\env\\Lib\\site-packages\\shap\\maskers\\_image.py:14\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_masker\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Masker\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcv2\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     16\u001b[39m     record_import_error(\u001b[33m\"\u001b[39m\u001b[33mcv2\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcv2 could not be imported!\u001b[39m\u001b[33m\"\u001b[39m, e)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "# SHAP Explanation\n",
    "def explain_with_shap(model, images, class_names, num_explanations=5):\n",
    "    \"\"\"\n",
    "    Generate SHAP explanations for the model predictions\n",
    "    \n",
    "    Args:\n",
    "        model: Trained Keras model\n",
    "        images: Numpy array of preprocessed images\n",
    "        class_names: List of class names\n",
    "        num_explanations: Number of explanations to generate and display\n",
    "    \"\"\"\n",
    "    # Select a subset of images to explain\n",
    "    if len(images) > num_explanations:\n",
    "        images = images[:num_explanations]\n",
    "    \n",
    "    # Create a masker that is used to mask out partitions of the input image\n",
    "    masker = shap.maskers.Image(\"inpaint_telea\", images[0].shape)\n",
    "    \n",
    "    # Create an explainer with the model and image masker\n",
    "    explainer = shap.Explainer(model, masker, output_names=class_names)\n",
    "    \n",
    "    print(\"Generating SHAP explanations... (This may take a while)\")\n",
    "    # Compute SHAP values\n",
    "    shap_values = explainer(images, max_evals=500, batch_size=32, outputs=shap.Explanation.argsort.flip[:4])\n",
    "    \n",
    "    # Plot explanations for each image\n",
    "    for i in range(len(images)):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Get the true and predicted class\n",
    "        true_class = class_names[test_labels[i]]\n",
    "        pred_class = class_names[np.argmax(predictions[i])]\n",
    "        confidence = np.max(predictions[i])\n",
    "        \n",
    "        # Plot the original image\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(f\"Original\\nTrue: {true_class}\\nPred: {pred_class} ({confidence:.2f})\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Plot SHAP explanations for top predicted class\n",
    "        plt.subplot(1, 3, 2)\n",
    "        shap.image_plot([shap_values[i][:, :, :, np.argmax(predictions[i])]], images[i:i+1], show=False)\n",
    "        plt.title(f\"SHAP - {pred_class}\")\n",
    "        \n",
    "        # Plot SHAP explanations for true class (if different from predicted)\n",
    "        if test_labels[i] != np.argmax(predictions[i]):\n",
    "            plt.subplot(1, 3, 3)\n",
    "            shap.image_plot([shap_values[i][:, :, :, test_labels[i]]], images[i:i+1], show=False)\n",
    "            plt.title(f\"SHAP - {true_class}\")\n",
    "        else:\n",
    "            plt.subplot(1, 3, 3)\n",
    "            second_class = np.argsort(predictions[i])[-2]  # Second most likely class\n",
    "            shap.image_plot([shap_values[i][:, :, :, second_class]], images[i:i+1], show=False)\n",
    "            plt.title(f\"SHAP - {class_names[second_class]}\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the explanation\n",
    "        explanation_path = f\"explanations/explanation_{i}.png\"\n",
    "        plt.savefig(explanation_path, bbox_inches='tight', dpi=150)\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"Explanation saved to {explanation_path}\")\n",
    "\n",
    "# Generate explanations for the first 5 images\n",
    "explain_with_shap(model, test_images, class_names, num_explanations=5)\n",
    "\n",
    "print(\"\\nSHAP explanations completed successfully!\")\n",
    "print(f\"Explanation images saved to 'explanations' directory\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
